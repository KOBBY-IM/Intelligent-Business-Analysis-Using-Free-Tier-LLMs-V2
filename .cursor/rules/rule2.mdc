---
alwaysApply: true
---
description: /streamlit|rag|llm evaluation/i
#####

Title: Project-Specific Execution Rule — Free-Tier LLM Evaluation System

Applies to: Tasks for "Intelligent Business Analysis Using Free-Tier LLMs"

Rule:
This project targets a multi-model RAG-based LLM evaluation platform, deployed on **Streamlit Cloud**, under tight architectural and resource constraints. Every related task must align with these principles:

1. Streamlit Cloud Compliance  
• All modules must run reliably in the ephemeral Streamlit Cloud environment.  
• No reliance on `localhost`, persistent file systems, or untested packages.  
• Use Streamlit session state for temporary state and secrets for config.

2. Four Free-Tier LLMs  
• Integrate exactly four LLMs from Groq, Gemini, and OpenRouter using approved APIs (e.g., `litellm`).  
• Responses must be grounded in retrieved data when applicable.

3. Modular RAG Implementation  
• RAG must be implemented with separate modules for:  
 – Ingestion  
 – Chunking  
 – Embedding  
 – Vector database  
 – Retrieval  
• Use lightweight, embeddable vector DBs (e.g., Chroma in client-only mode).  
• Optimize for 70%+ context coverage from retrieval.

4. Blind Human Evaluation System  
• Only one evaluation per tester email.  
• Responses from LLMs must be anonymized and shuffled.  
• Use pregenerated questions/answers only.  
• Collect structured, linked feedback (ratings + qualitative).  
• Store data securely (prefer CSV/JSON or cloud store).

5. Technical Batch Evaluator  
• Implement as an external, automated script.  
• Runs 14× per 12-hour window over 4 days.  
• Must export daily metrics (latency, throughput, failures) to persistent cloud storage.  
• Streamlit reads this data only for display.

6. Access Control  
• Use Streamlit secrets for admin/tester access.  
• Admin-only pages must be fully isolated.

Deliverables must be designed with these non-negotiable constraints in mind. Misalignment = rework.

#####
