# Project Organization Guide

## Overview

This document outlines the organized file structure of the Intelligent Business Analysis Using Free-Tier LLMs project.

## Directory Structure

```
Intelligent-Business-Analysis-Using-Free-Tier-LLMs-V2/
â”œâ”€â”€ ğŸ“ Core Application
â”‚   â”œâ”€â”€ app.py                          # Main Streamlit application
â”‚   â”œâ”€â”€ requirements.txt                 # Python dependencies
â”‚   â””â”€â”€ README.md                       # Project overview
â”‚
â”œâ”€â”€ ğŸ“ Pages (Streamlit Pages)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analysis.py                     # Analysis dashboard
â”‚   â”œâ”€â”€ blind_evaluation.py             # Human blind evaluation interface
â”‚   â”œâ”€â”€ blind_evaluation_analysis.py    # Blind evaluation results analysis
â”‚   â”œâ”€â”€ llm_health_check.py             # LLM connectivity testing
â”‚   â”œâ”€â”€ provider_comparison.py          # Provider-level analysis
â”‚   â”œâ”€â”€ rag_demo.py                     # RAG pipeline demonstration
â”‚   â”œâ”€â”€ technical_metrics_analysis.py   # Technical performance analysis
â”‚   â””â”€â”€ technical_metrics_analysis_backup.py
â”‚
â”œâ”€â”€ ğŸ“ Utils (Core Utilities)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auth.py                         # Authentication system
â”‚   â”œâ”€â”€ chunking.py                     # Text chunking utilities
â”‚   â”œâ”€â”€ data_loader.py                  # Data loading utilities
â”‚   â”œâ”€â”€ data_store.py                   # Data storage management
â”‚   â”œâ”€â”€ embedding.py                    # Embedding generation
â”‚   â”œâ”€â”€ llm_clients.py                  # LLM API clients
â”‚   â”œâ”€â”€ pregenerate_responses.py        # Response generation
â”‚   â”œâ”€â”€ prompts.py                      # Prompt templates
â”‚   â”œâ”€â”€ question_generator.py           # Question generation
â”‚   â”œâ”€â”€ rag_pipeline.py                 # RAG pipeline orchestration
â”‚   â”œâ”€â”€ registration.py                 # User registration
â”‚   â””â”€â”€ vector_db.py                    # Vector database operations
â”‚
â”œâ”€â”€ ğŸ“ Analysis Scripts
â”‚   â”œâ”€â”€ README.md                       # Analysis scripts documentation
â”‚   â”œâ”€â”€ analyze_data.py                 # Comprehensive data analysis
â”‚   â”œâ”€â”€ test_4_question_implementation.py # 4-question implementation testing
â”‚   â”œâ”€â”€ question_reduction_impact_analysis.py # Question reduction analysis
â”‚   â”œâ”€â”€ question_reduction_analysis.py  # General question reduction analysis
â”‚   â””â”€â”€ random_selection_analysis.py    # Random selection strategy analysis
â”‚
â”œâ”€â”€ ğŸ“ Tests
â”‚   â”œâ”€â”€ README.md                       # Testing documentation
â”‚   â”œâ”€â”€ unit/                           # Unit tests
â”‚   â”‚   â””â”€â”€ test_error_tracking.py      # Error tracking tests
â”‚   â””â”€â”€ integration/                    # Integration tests (to be added)
â”‚
â”œâ”€â”€ ğŸ“ Documentation
â”‚   â”œâ”€â”€ README.md                       # Documentation overview
â”‚   â”œâ”€â”€ implementation/                 # Implementation documentation
â”‚   â”‚   â”œâ”€â”€ METHODOLOGY.md              # Academic thesis methodology
â”‚   â”‚   â”œâ”€â”€ 4_QUESTION_IMPLEMENTATION.md # 4-question implementation
â”‚   â”‚   â”œâ”€â”€ ERROR_TRACKING_ENHANCEMENTS.md # Error tracking system
â”‚   â”‚   â”œâ”€â”€ PROVIDER_ANALYSIS_ENHANCEMENTS.md # Provider analysis features
â”‚   â”‚   â””â”€â”€ DATA_COLLECTION_SYSTEM.md   # Data collection architecture
â”‚   â”œâ”€â”€ deployment/                     # Deployment documentation
â”‚   â”‚   â”œâ”€â”€ STREAMLIT_CLOUD_SETUP.md    # Streamlit Cloud setup
â”‚   â”‚   â”œâ”€â”€ STREAMLIT_CLOUD_DEPLOYMENT_CHECKLIST.md # Deployment checklist
â”‚   â”‚   â”œâ”€â”€ STREAMLIT_CLOUD_TROUBLESHOOTING.md # Troubleshooting guide
â”‚   â”‚   â”œâ”€â”€ DEPLOYMENT_READY_CHECKLIST.md # Pre-deployment checklist
â”‚   â”‚   â””â”€â”€ SESSION_PERSISTENCE_IMPROVEMENTS.md # Session management
â”‚   â”œâ”€â”€ analysis/                       # Analysis documentation
â”‚   â”‚   â””â”€â”€ DATA_COLLECTION_REVIEW.md   # Data collection review
â”‚   â””â”€â”€ testing/                        # Testing documentation
â”‚       â”œâ”€â”€ BATCH_TESTING_STATUS.md     # Batch testing status
â”‚       â”œâ”€â”€ REGISTRATION_TESTING.md     # Registration testing
â”‚       â”œâ”€â”€ local_test_checklist.md     # Local testing checklist
â”‚       â”œâ”€â”€ HOW_TO_TEST_PHASE3.md       # Phase 3 testing guide
â”‚       â””â”€â”€ ISSUES_FIXED_SUMMARY.md     # Fixed issues summary
â”‚
â”œâ”€â”€ ğŸ“ Automation
â”‚   â”œâ”€â”€ batch_evaluator.py              # Automated batch evaluation
â”‚   â”œâ”€â”€ dashboard.py                    # Monitoring dashboard
â”‚   â”œâ”€â”€ local_scheduler.py              # Local task scheduling
â”‚   â”œâ”€â”€ monitor.py                      # System monitoring
â”‚   â”œâ”€â”€ real_world_simulator.py         # Real-world simulation
â”‚   â”œâ”€â”€ run_real_world_sim.sh           # Simulation runner
â”‚   â”œâ”€â”€ run_scheduler.sh                # Scheduler runner
â”‚   â”œâ”€â”€ batch-evaluator.service         # System service
â”‚   â””â”€â”€ README.md                       # Automation documentation
â”‚
â”œâ”€â”€ ğŸ“ Scripts
â”‚   â”œâ”€â”€ README.md                       # Scripts documentation
â”‚   â”œâ”€â”€ setup/                          # Setup scripts
â”‚   â”‚   â”œâ”€â”€ setup_gcs.py                # GCS setup
â”‚   â”‚   â”œâ”€â”€ setup_gcs.sh                # GCS setup shell script
â”‚   â”‚   â””â”€â”€ configure_gcs.py            # GCS configuration
â”‚   â””â”€â”€ deployment/                     # Deployment scripts (to be added)
â”‚
â”œâ”€â”€ ğŸ“ Data
â”‚   â”œâ”€â”€ batch_eval_metrics.csv          # Batch evaluation metrics
â”‚   â”œâ”€â”€ eval_questions.json             # Evaluation questions
â”‚   â””â”€â”€ evaluations.json                # Human evaluation data
â”‚
â”œâ”€â”€ ğŸ“ Samples
â”‚   â”œâ”€â”€ README.md                       # Sample data documentation
â”‚   â”œâ”€â”€ create_sample_batch_data.py     # Sample batch data generator
â”‚   â”œâ”€â”€ create_sample_blind_data.py     # Sample blind evaluation data
â”‚   â””â”€â”€ generate_sample_data.py         # General sample data generator
â”‚
â”œâ”€â”€ ğŸ“ Debug
â”‚   â”œâ”€â”€ README.md                       # Debug documentation
â”‚   â””â”€â”€ debug_session.py                # Debug session utilities
â”‚
â””â”€â”€ ğŸ“ Configuration Files
    â”œâ”€â”€ .gitignore                      # Git ignore rules
    â”œâ”€â”€ .streamlit/                     # Streamlit configuration
    â”œâ”€â”€ .devcontainer/                  # Development container config
    â”œâ”€â”€ .github/                        # GitHub configuration
    â”œâ”€â”€ .cursor/                        # Cursor IDE configuration
    â””â”€â”€ .pytest_cache/                  # Pytest cache
```

## File Categories

### **Core Application Files**
- **`app.py`**: Main Streamlit application entry point
- **`requirements.txt`**: Python package dependencies
- **`README.md`**: Project overview and setup instructions

### **Streamlit Pages**
- **Analysis Pages**: Data analysis and visualization interfaces
- **Evaluation Pages**: Human blind evaluation system
- **Demo Pages**: System demonstration and testing interfaces

### **Utility Modules**
- **Authentication**: User authentication and access control
- **Data Processing**: Data loading, storage, and manipulation
- **LLM Integration**: API clients and response handling
- **RAG Pipeline**: Retrieval-augmented generation system
- **Vector Database**: Embedding storage and retrieval

### **Analysis Scripts**
- **Data Analysis**: Comprehensive analysis of evaluation results
- **Question Analysis**: Analysis of question selection strategies
- **Implementation Testing**: Validation of system features

### **Testing**
- **Unit Tests**: Individual component testing
- **Integration Tests**: System integration testing
- **Error Tracking**: Error handling and classification testing

### **Documentation**
- **Implementation**: Core system implementation guides
- **Deployment**: Deployment and infrastructure guides
- **Analysis**: Research and analysis documentation
- **Testing**: Testing procedures and validation guides

### **Automation**
- **Batch Evaluation**: Automated LLM performance testing
- **Monitoring**: System monitoring and health checks
- **Scheduling**: Task scheduling and automation

### **Scripts**
- **Setup**: Infrastructure and environment setup
- **Deployment**: Deployment and maintenance automation
- **Configuration**: System configuration management

### **Data**
- **Evaluation Data**: Human evaluation results
- **Metrics Data**: Technical performance metrics
- **Question Data**: Evaluation question definitions

### **Samples**
- **Sample Data**: Test data generators
- **Example Data**: Sample datasets for testing

## Organization Benefits

### **Improved Navigation**
- Logical grouping of related files
- Clear separation of concerns
- Easy-to-follow directory structure

### **Better Maintenance**
- Organized documentation by category
- Separated testing and analysis scripts
- Clear distinction between core and utility files

### **Enhanced Development**
- Easy to locate specific functionality
- Clear module dependencies
- Simplified testing and debugging

### **Scalability**
- Easy to add new features
- Organized space for future components
- Clear patterns for new additions

## Usage Guidelines

### **Adding New Files**
1. **Core Features**: Add to appropriate `utils/` module
2. **New Pages**: Add to `pages/` directory
3. **Analysis Scripts**: Add to `analysis_scripts/`
4. **Tests**: Add to appropriate `tests/` subdirectory
5. **Documentation**: Add to appropriate `docs/` subdirectory

### **File Naming Conventions**
- **Python Files**: Use snake_case (e.g., `data_loader.py`)
- **Documentation**: Use UPPERCASE with underscores (e.g., `METHODOLOGY.md`)
- **Scripts**: Use descriptive names with clear purpose
- **Tests**: Prefix with `test_` (e.g., `test_error_tracking.py`)

### **Documentation Standards**
- Each directory has a `README.md` explaining its purpose
- Implementation details documented in `docs/implementation/`
- Deployment procedures documented in `docs/deployment/`
- Testing procedures documented in `docs/testing/`

This organization provides a clean, maintainable, and scalable structure for the LLM evaluation system. 